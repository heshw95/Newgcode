# -*- coding: utf-8 -*-
"""FZI_supervised (upload version).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k2bQ0F7cYwFNd5QMm9f3kB0mAqfXIV8y
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import io

df=pd.read_csv('/content/data entry.csv')

df.columns = [x.lower() for x in df.columns]

df[['phi','k(md)','sw',"r35"]].describe()

df['sample'].astype("string") 
df.head()

y= df["fzi"]
X_1=df[['sample','k(md)','phi','sw','r35']]


from sklearn.model_selection import train_test_split


x_train,x_test,y_train, y_test= train_test_split(X_1,y,random_state=42,train_size=0.75)

x_tr_samp=x_train.sample
x_test_samp=x_test.sample

x_train2=x_train.drop(['sample'],axis=1)
x_test2=x_test.drop(['sample'],axis=1)


from sklearn.metrics import mean_absolute_error,r2_score
from xgboost import XGBRegressor

xgb=XGBRegressor(objective= "reg:squarederror",random_state=42)
xgb.fit(x_train2,y_train)
y_pred=xgb.predict(x_test2)
mae=mean_absolute_error(y_test,y_pred)
r2=r2_score(y_test,y_pred)

print("mae score is for  is : {}".format(mae))
print("r2 score is: " + str (r2))

from sklearn.model_selection import cross_val_score
mn=np.mean(cross_val_score(xgb, x_train2, y_train, cv=4))
print(mn)



pip install bayesian-optimization
from bayes_opt import BayesianOptimization


param_bounds = {
    'learning_rate': (0.01, 1.0),
    'n_estimators': (100, 1000),
    'max_depth': (3,10),
    'subsample': (1.0, 1.0),   
    'colsample': (1.0, 1.0),   
    'gamma': (0, 5)}

def xgboost_hyper_params(learning_rate,
                        n_estimators,
                        max_depth,
                        subsample,
                        colsample,
                        gamma):

    max_depth = int(max_depth)
    n_estimators = int(n_estimators)

    clf = xgb(
        max_depth=max_depth,
        learning_rate=learning_rate,
        n_estimators=n_estimators,
        gamma=gamma)
    return np.mean(cross_val_score(clf, x_train2, y_train, cv=4, scoring='roc_auc'))

optimizer = BayesianOptimization(
    f=xgboost_hyper_params,
    pbounds=param_bounds,
    random_state=42,
)


from xgboost import plot_importance
plot_importance(xgb)
plt.savefig('f-i.png', dpi=600)

plt.show()



plt.bar(range(len(xgb.feature_importances_)),xgb.feature_importances_, )
plt.xticks(range(4),["perm", "phi", "Sw","r35"])

xgb_feat=xgb.feature_importances_
# get importance
importance = xgb.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))

pip install shap

x_test2.columns
df_full=[x_train2,x_test2] 
df_total= pd.concat(df_full).reset_index(drop=True)
df_total.head()

import shap 
explainer = shap.TreeExplainer(xgb)
shap.initjs()
shap_values = explainer.shap_values(df_total)
shap.summary_plot(shap_values, df_total)

all_dfs=[x_train2,x_test2]
x_full = pd.concat(all_dfs).reset_index(drop=True)

explainer = shap.TreeExplainer(xgb)
shap.initjs()
shap_values = explainer.shap_values(x_test2)
shap.summary_plot(shap_values, x_test2)


y_train_pred=xgb.fit(x_train2,y_train).predict(x_train2)

x_test_df=x_test
x_test_df['fzi_measured'] = y_test
x_test_df['fzi_estimated']=y_pred
x_test_df["dataset"]= "Test dataset"
x_test_df.to_csv("X_test_cv_4__indexed.csv",index=True,)

x_train_df=x_train
x_train_df['fzi_measured'] = y_train
x_train_df['fzi_estimated']=xgb.fit(x_train2,y_train).predict(x_train2)
x_train_df["dataset"]= "Training dataset"
x_train_df.to_csv("X_train_cv_4_indexed.csv",index=True)


df_both=[x_test_df,x_train_df]
df_both_con=pd.concat(df_both)
df_both_con.to_csv("combined.csv",index=True)


import math
df['sample'].astype("string") 
df.head()
df["k(md)_log"] = [math.log(x) for x in df["k(md)"]]
df["fzi_log"] = [math.log(x) for x in df["fzi"]]

y= df2["fzi"]
X_1=df2[['k(md)_log','phi','sw','r35']]

from sklearn.cluster import MeanShift

ms = MeanShift()
ms.fit(X_2)
labels=ms.labels_

plt.scatter(X_5["k(md)_log"],X_5["phi"],c=labels)
plt.xlabel("perm (md)")
plt.ylabel("phi")
plt.title("Meanshift")
plt.plot()


from sklearn.cluster import KMeans
Km=KMeans(n_clusters=4)
Km.fit(X_2)
labels2= Km.predict(X_2)
cent= Km.cluster_centers_

inertia_list=[]

for k in np.arange(2,10):
    Km=KMeans(n_clusters=k)
    Km.fit(X_2)
    inertia_list.append(Km.inertia_)
inertia_list


plt.plot(np.arange(2,10),inertia_list, '-ro')
plt.xlabel("No. of clusters")
plt.ylabel("Inertia")

plt.savefig('inertia.png', dpi=600, format='png')



outpt=X_1
outpt["sample"]=df["sample"]
outpt["labels_meanshif"]=labels
outpt["labels_Kmeans"]=labels2
outpt["K(md)"]= df['k(md)']
outpt.head()
outpt.to_csv("output_unsupervised_2.csv",index=False)


